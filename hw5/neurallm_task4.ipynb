{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5Yox0gG1DsF"
   },
   "source": [
    "Homework 5: Neural Language Models  (& ðŸŽƒ SpOoKy ðŸ‘» authors ðŸ§Ÿ data) - Task 4\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: __Adrian Criollo__ (Write these in every notebook you submit.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxWlOU9k1DsQ"
   },
   "source": [
    "Task 4: Compare your generated sentences (15 points)\n",
    "----\n",
    "\n",
    "In this task, you'll analyze one of the files that you produced in Task 3. You'll need to compare against the corresponding file that we have provided for you that was generated from the vanilla n-gram language model.\n",
    "\n",
    "Choose *__one__* of the following two options.\n",
    "\n",
    "Option 1: Evaluate the generated words of *character*-based models\n",
    "---\n",
    "\n",
    "Your job for this option is to programmatically measure two things:\n",
    "1. the percentage of words produced by each model that are valid english words.\n",
    "2. the percentage of words produced by each model that are valid english words *and* were not seen at train time.\n",
    "\n",
    "For this task, a word is defined as \"characters between _ \" or \"characters between spaces\" (if you replaced your underscores with spaces when you printed out your new sentences).\n",
    "\n",
    "\n",
    "Make sure to turn in any necessary supporting files along with your submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\adria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# your imports here\n",
    "import neurallm_utils as nutils\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "import pandas as pd\n",
    "\n",
    "generated_file = 'generated_sentences_char.txt'\n",
    "vanilla_generated_file = 'spooky_vanilla_3_char.txt'\n",
    "FILE_PATH = 'spooky_author_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Character-Based Model:\n",
      "Percentage of valid English words: 95.10829885616938%\n",
      "Percentage of valid English words not seen during training: 0.0%\n",
      "\n",
      "Vanilla N-Gram Model:\n",
      "Percentage of valid English words: 41.656942823803966%\n",
      "Percentage of valid English words not seen during training: 5.805134189031505%\n"
     ]
    }
   ],
   "source": [
    "# code here!\n",
    "\n",
    "with open(generated_file, 'r', encoding='utf-8') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "with open(vanilla_generated_file, 'r', encoding='utf-8') as f:\n",
    "    sentences_vanilla = f.readlines()\n",
    "\n",
    "def tokenize_sentences(sentences, by_char=False):\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        tokens = nutils.tokenize_line(\n",
    "            line=sentence,\n",
    "            ngram=1,\n",
    "            by_char=by_char,\n",
    "            space_char=' ',\n",
    "            sentence_begin='<s>',\n",
    "            sentence_end='</s>'\n",
    "        )\n",
    "        words.extend(tokens)\n",
    "    return words\n",
    "\n",
    "words_my_model = tokenize_sentences(sentences, by_char=False)\n",
    "words_vanilla_model = tokenize_sentences(sentences_vanilla, by_char=False)\n",
    "\n",
    "english_words = words.words()\n",
    "english_words_set = set(word.lower() for word in english_words)\n",
    "\n",
    "train_data_df = pd.read_csv(FILE_PATH)\n",
    "train_sentences = train_data_df['text'].tolist()\n",
    "train_words = tokenize_sentences(train_sentences, by_char=False)\n",
    "train_words_set = set(word.lower() for word in train_words)\n",
    "\n",
    "def compute_percentages(words_list, english_words_set, train_words_set):\n",
    "    total_words = len(words_list)\n",
    "    words_lower = [word.lower() for word in words_list]\n",
    "    valid_english_words = [word for word in words_lower if word in english_words_set]\n",
    "    valid_new_words = [word for word in valid_english_words if word not in train_words_set]\n",
    "    percentage_valid_english = (len(valid_english_words) / total_words) * 100 if total_words > 0 else 0\n",
    "    percentage_valid_new_words = (len(valid_new_words) / total_words) * 100 if total_words > 0 else 0\n",
    "\n",
    "    return percentage_valid_english, percentage_valid_new_words\n",
    "\n",
    "percentage_valid_english_my_model, percentage_valid_new_words_my_model = compute_percentages(\n",
    "    words_my_model, english_words_set, train_words_set\n",
    ")\n",
    "\n",
    "percentage_valid_english_vanilla_model, percentage_valid_new_words_vanilla_model = compute_percentages(\n",
    "    words_vanilla_model, english_words_set, train_words_set\n",
    ")\n",
    "\n",
    "\n",
    "print(\"My Character-Based Model:\")\n",
    "print(f\"Percentage of valid English words: {percentage_valid_english_my_model}%\")\n",
    "print(f\"Percentage of valid English words not seen during training: {percentage_valid_new_words_my_model}%\\n\")\n",
    "\n",
    "print(\"Vanilla N-Gram Model:\")\n",
    "print(f\"Percentage of valid English words: {percentage_valid_english_vanilla_model}%\")\n",
    "print(f\"Percentage of valid English words not seen during training: {percentage_valid_new_words_vanilla_model}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How did you determine what a valid english word is? __I determined if it was a valid english word by comparing it to NLTK's word corpus.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Gather the sequences of characters that are determined not to be words. Sampling at minimum 100 of these sequences, how many of them *should have* been counted as words in your opinion? __Looking at a sample of 100 invalid words I saw maybe 2 words that should have been counted.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model        sequence\n",
      "478   vanilla           fifte\n",
      "821   vanilla          whican\n",
      "1979  vanilla     thadinedged\n",
      "2185  vanilla           alles\n",
      "2080  vanilla          notime\n",
      "...       ...             ...\n",
      "1963  vanilla           exper\n",
      "361   vanilla  andieflethimor\n",
      "1060  vanilla      ouprovered\n",
      "1203  vanilla        subtally\n",
      "254   vanilla           linto\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# more code here, as needed!\n",
    "\n",
    "my_model = [('neural', word) for word in words_my_model]\n",
    "vanilla_model = [('vanilla', word) for word in words_vanilla_model]\n",
    "combined_data = my_model + vanilla_model\n",
    "\n",
    "valid_words = []\n",
    "invalid_words = []\n",
    "\n",
    "for model_label, word in combined_data:\n",
    "    word_lower = word.lower()\n",
    "    if word_lower in english_words_set:\n",
    "        valid_words.append({'model': model_label, 'sequence': word})\n",
    "    else:\n",
    "        invalid_words.append({'model': model_label, 'sequence': word})\n",
    "\n",
    "df_valid_words = pd.DataFrame(valid_words)\n",
    "df_invalid_words = pd.DataFrame(invalid_words)\n",
    "df_valid_words = df_valid_words.drop_duplicates()\n",
    "df_invalid_words = df_invalid_words.drop_duplicates()\n",
    "df_valid_words.to_csv('valid_words_lms.csv', index=False)\n",
    "df_invalid_words.to_csv('invalid_words_lms.csv', index=False)\n",
    "\n",
    "total_invalid_sequences = len(df_invalid_words)\n",
    "sample_size = min(100, total_invalid_sequences)\n",
    "\n",
    "sampled_sequences = df_invalid_words.sample(n=sample_size, random_state=42)\n",
    "print(sampled_sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit two csv files alongside this notebook: `valid_words_lms.csv` and `invalid_words_lms.csv`. Both files should have __two__ columns: `model`, `sequence`. `model` will have the value `neural` or `vanilla`. `sequence` will be the corresponding sequence of characters. `valid_words_lms.csv` should contain all sequences from both models you determined to be valid words. `invalid_words_lms.csv` will have all sequences from both models you programatically determined to be invalid words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "316H0xSh1DsQ"
   },
   "source": [
    "Option 2: Evaluate the generated sentences of *word*-based models\n",
    "----\n",
    "\n",
    "Your job for this option is to measure the quality of your generated sentences for word-based models. For this option you *must* survey at least 3 people who are __not__ in this course. They need to speak and read the language that you are evaluating, but they need not be native speakers.\n",
    "\n",
    "You will evaluate the quality of the generated sentences in the following way:\n",
    "1. Generate 20 sentences from your neural model.\n",
    "2. Using the same level of n-gram, pair these sentences with provided sentences from the vanilla n-gram model.\n",
    "\n",
    "Next, build a survey. For each pair of (neural LM sentence, vanilla n-ngram LM sentence), you'll ask the survey taker two binary selection questions:\n",
    "1. which sentence is more grammatical?\n",
    "2. which sentence makes more sense, semantically (in meaning)?\n",
    "3. Which sentence do you prefer?\n",
    "\n",
    "\n",
    "Finally, you'll evaluate your survey results. Calculate the following:\n",
    "1. What percentage of neural vs. vanilla n-gram LM sentences were preferred, separated along each of the three dimensions?\n",
    "2. What is [Krippendorff's alpha](https://en.wikipedia.org/wiki/Krippendorff%27s_alpha) for your survey data? \n",
    "\n",
    "You are welcome to use a pre-built python implmenetation of the Krippendorff's alpha calculation, such as [this one](https://pypi.org/project/krippendorff/). Krippendorff's alpha is one way to measure interannotator agreement â€” the extent to which your survey respondants agree with one another.\n",
    "\n",
    "You will submit your survey data alongside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'krippendorff'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# your imports here\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkrippendorff\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'krippendorff'"
     ]
    }
   ],
   "source": [
    "# your imports here\n",
    "\n",
    "import krippendorff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "wordembeddings_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05041e657fa0436a83611a3d2d345b99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cd0685004814c0d974a1d809e0e2b4f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b0dca775977048f38841afae3d906eb6",
      "value": "100%"
     }
    },
    "140057e9712f46af9ebf5825ef9b1390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05041e657fa0436a83611a3d2d345b99",
       "IPY_MODEL_a818afa6bb4f43c8b7e32a3c04f17211",
       "IPY_MODEL_72a47718e310461fbd61b312f7bf7cfe"
      ],
      "layout": "IPY_MODEL_488b55855d4d4ffc8af6d3d77aa3fdf8"
     }
    },
    "150adc7de7f54d63a215482e6a977067": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b93060412f54083b6dd7b9203ae55d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cd0685004814c0d974a1d809e0e2b4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "488b55855d4d4ffc8af6d3d77aa3fdf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a47718e310461fbd61b312f7bf7cfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d9e5b3a1e144e6b34a55ab5cbce43f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_150adc7de7f54d63a215482e6a977067",
      "value": " 19579/19579 [00:00&lt;00:00, 18295.70it/s]"
     }
    },
    "843343b9adc84d949f839d51814d55aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4d9e5b3a1e144e6b34a55ab5cbce43f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a818afa6bb4f43c8b7e32a3c04f17211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b93060412f54083b6dd7b9203ae55d0",
      "max": 19579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_843343b9adc84d949f839d51814d55aa",
      "value": 19579
     }
    },
    "b0dca775977048f38841afae3d906eb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
